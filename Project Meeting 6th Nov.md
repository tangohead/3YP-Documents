**Project Meeting Notes - 6th November**

**Sampling**
* KL-Divergence compares degree distributions for how close they are. Gets degree from original graph rather than sample.
* Need to compare post-sample degree distributions too.
* H-Betweeness is a local estimate of betweenness. 
* Plot on log scale.

**Doc**
* SandTable input
* Right Direction
* Think of things as probabilities
* Decision trees, keep the nodes simple
	* Not necessarily the same as ML
	* ML classifies at multiple levels
	* AI one - games dev idea
	* Series of states, deciding next state
	* Builds a tree of states that each person follows. Each branch has a probability idea.
	* Important attributes go up at the top
	* Needs to be super efficient
	* Goes through tree and takes branches based on own attributes, e.g. 'is a smoker' goes either yes or no, then on to further, relevant decisions (i.e. if smoker, go up or down on no. of cigarettes). Will adjust the attributes/
	* Happens on every tick, follows this similar decision process. 
* Start small, but plan big. Start working with two or three attributes.
* Act of God is useful - happens in real life.
* Break tree in to separate trees, especially with respect to reconfiguring the network.
* Directed edges are very useful. Can have a cleanup section of the tree, tries to maintain reciprocating friendship, so needs to average out reciprocation. Score it against an ideal number of friendships, add some if necessary. Lower edge threshold.

**ACTION**
Draft project report for next week - design, implement, literature.

